# eCourts Scraper (Intern Task)

A Python-based web scraper for fetching court case listings from the eCourts India portal. This tool helps check if a case is listed for today or tomorrow, and can download case PDFs and cause lists.

## ğŸ¯ Project Goal

Build a Python script to fetch court listings from [eCourts](https://services.ecourts.gov.in/ecourtindia_v6/) with the following capabilities:

1. âœ… Input case details (CNR or Case Type/Number/Year)
2. âœ… Check if case is listed today or tomorrow  
3. âœ… Show serial number and court name if listed
4. âœ… Download case PDFs (if available)
5. âœ… Download entire cause list for today
6. âœ… CLI interface with multiple options
7. âœ… Optional web API interface
8. âœ… Save results as JSON files

**Deadline:** 20th October 2024

## ğŸ“ Project Structure

```
ecourts_scraper/
â”œâ”€â”€ scraper.py              # Main CLI script
â”œâ”€â”€ api_app.py             # Optional Flask API wrapper
â”œâ”€â”€ test_scraper.py        # Test script
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ example_output.json    # Sample output format
â”œâ”€â”€ README.md             # This file
â”œâ”€â”€ LICENSE               # MIT license
â””â”€â”€ outputs/              # Output directory
    â”œâ”€â”€ cases/           # Downloaded case PDFs
    â”œâ”€â”€ causelists/      # Downloaded cause list PDFs
    â””â”€â”€ *.json          # Search results
```

## ğŸš€ Quick Start

### 1. Setup Environment

```bash
# Clone or download the project
# Navigate to project directory

# Create virtual environment (recommended)
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Basic Usage

```bash
# Check case by CNR for today
python scraper.py --cnr "MHMU01234567890123" --today

# Check case by type/number/year for tomorrow
python scraper.py --type "CR" --number 123 --year 2024 --tomorrow

# Check case for specific date
python scraper.py --cnr "DLCT01234567890123" --date "2024-10-20"

# Download cause list for today
python scraper.py --causelist --today --download-pdf

# Get help
python scraper.py --help
```

### 3. Run Tests

```bash
# Run the test suite
python test_scraper.py
```

### 4. Start API Server (Optional)

```bash
# Start Flask API server
python api_app.py

# Test API endpoints
curl -X POST http://localhost:5001/check \
  -H "Content-Type: application/json" \
  -d '{"cnr":"MHMU01234567890123","date":"2024-10-20"}'
```

## ğŸ“– Detailed Usage

### Command Line Options

#### Case Identification
- `--cnr <CNR>` - Full CNR string (e.g., MHMU01234567890123)
- `--type <TYPE>` - Case type (CR, CIV, FA, CC, etc.)
- `--number <NUM>` - Case number
- `--year <YEAR>` - Case year

#### Date Selection
- `--today` - Check for today's date
- `--tomorrow` - Check for tomorrow's date  
- `--date <YYYY-MM-DD>` - Check for specific date

#### Actions
- `--causelist` - Download entire cause list
- `--download-pdf` - Download any found PDFs

### Examples

```bash
# Search by CNR for today
python scraper.py --cnr "MHMU01234567890123" --today

# Search by case details for tomorrow
python scraper.py --type "CR" --number 456 --year 2024 --tomorrow

# Download cause list with PDFs
python scraper.py --causelist --today --download-pdf

# Search for specific date
python scraper.py --cnr "DLCT01234567890123" --date "2024-10-25"
```

### API Usage

Start the API server:
```bash
python api_app.py
```

API Endpoints:

**POST /check** - Check specific case
```json
{
  "cnr": "MHMU01234567890123",
  "date": "2024-10-20"
}
```

**POST /causelist** - Get cause list
```json
{
  "date": "2024-10-20"
}
```

## ğŸ“„ Output Format

Results are saved as JSON files in the `outputs/` directory:

```json
{
  "query": {
    "case_identifier": "MHMU01234567890123",
    "date_checked": "2024-10-20",
    "timestamp": "2024-10-14T10:30:00"
  },
  "listed": true,
  "serial_number": "5",
  "court_name": "District Court, Mumbai",
  "matched_line": "5. CR 123/2024 - State vs. John Doe",
  "case_pdf_link": "https://...",
  "case_pdf_saved": "outputs/cases/case_123.pdf"
}
```

## âš ï¸ Important Notes

### Website Limitations
- eCourts website structure may change frequently
- Some courts may not have online cause lists
- Anti-bot protections may limit scraping
- PDF availability varies by court

### Best Practices
- Use reasonable delays between requests
- Respect website terms of service
- Verify results manually for important cases
- Keep the scraper updated if website changes

### Troubleshooting

**Case not found:**
- Verify CNR format (16 characters)
- Check if court publishes online cause lists
- Try different date formats
- Case might not be listed on that date

**Download failures:**
- PDF might not be publicly available
- Network connectivity issues
- Website blocking automated requests

**Website changes:**
- Update URL patterns in `scraper.py`
- Modify parsing selectors as needed
- Consider using Selenium for dynamic content

## ğŸ§ª Testing

Run the comprehensive test suite:

```bash
python test_scraper.py
```

Tests include:
- CLI functionality
- Input validation
- Output file generation
- API import verification
- Error handling

## ğŸ”§ Development

### Adding New Features

1. **New Court Support:** Update URL patterns in `search_cause_list_for_case()`
2. **Better Parsing:** Enhance BeautifulSoup selectors
3. **PDF Processing:** Add PDF text extraction with pdfminer.six
4. **Database Storage:** Replace JSON with SQLite/PostgreSQL

### Code Structure

- `scraper.py` - Main CLI application
- `api_app.py` - Flask web API wrapper  
- `test_scraper.py` - Test suite
- `outputs/` - Generated files directory

## ğŸ“‹ Requirements Met

- âœ… Input case details (CNR or Case Type/Number/Year)
- âœ… Check if listed today or tomorrow
- âœ… Show serial number and court name
- âœ… Download case PDFs (when available)
- âœ… Download entire cause list
- âœ… Console output with status
- âœ… Save results as JSON files
- âœ… CLI options (--today, --tomorrow, --causelist)
- âœ… Optional web API interface
- âœ… Proper error handling
- âœ… Code quality and documentation
- âœ… GitHub submission ready

## ğŸ“ License

MIT License - see LICENSE file for details.

"# ecourts_scraper" 
